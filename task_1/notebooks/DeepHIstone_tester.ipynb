{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/mnemo5/tao/MLG/task_1/utils\n"
     ]
    }
   ],
   "source": [
    "%cd  /mnt/mnemo5/tao/MLG/task_1/utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  use DeepHistone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/mnemo5/tao/anaconda3/envs/py309_MLG/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import time\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "from data_loader import *\n",
    "from dataset import HistoneDataset_returngenenames\n",
    "from histone_loader import*\n",
    "from stratification import *\n",
    "\n",
    "\n",
    "from modified_DeepHistone_model import DeepHistone\n",
    "from DeepHistone_opt1 import DeepHistone_opt1\n",
    "from modified_DeepHistone_utils import model_train,model_eval,model_predict\n",
    "from modified_DeepHistone_utils import get_reshaped_data\n",
    "from modified_DeepHistone_utils import get_dict_from_data\n",
    "from modified_DeepHistone_utils import save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_save_folder=\"../data/DeepHistone/\"\n",
    "prefix=\"basic-model-\"#\"opt1-model-\" #\"basic-model-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_stamp=time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "Log_Format = \"%(levelname)s %(asctime)s - %(message)s\"\n",
    "logging.basicConfig(level=logging.INFO, filename=f\"{model_save_folder}{prefix}time{time_stamp}.log\",\n",
    "                    filemode=\"a\",format=Log_Format) # cant save into file in jupyter notebook through "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_name</th>\n",
       "      <th>chr</th>\n",
       "      <th>gene_start</th>\n",
       "      <th>gene_end</th>\n",
       "      <th>TSS_start</th>\n",
       "      <th>TSS_end</th>\n",
       "      <th>strand</th>\n",
       "      <th>gex</th>\n",
       "      <th>cell_line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SLC20A1</td>\n",
       "      <td>2</td>\n",
       "      <td>112645939</td>\n",
       "      <td>112663825</td>\n",
       "      <td>112658362</td>\n",
       "      <td>112658412</td>\n",
       "      <td>+</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C11orf58</td>\n",
       "      <td>11</td>\n",
       "      <td>16613132</td>\n",
       "      <td>16758340</td>\n",
       "      <td>16738643</td>\n",
       "      <td>16738693</td>\n",
       "      <td>+</td>\n",
       "      <td>2239.103328</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZSCAN9</td>\n",
       "      <td>6</td>\n",
       "      <td>28224886</td>\n",
       "      <td>28233487</td>\n",
       "      <td>28225263</td>\n",
       "      <td>28225313</td>\n",
       "      <td>+</td>\n",
       "      <td>19.798064</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gene_name  chr  gene_start   gene_end  TSS_start    TSS_end strand  \\\n",
       "0   SLC20A1    2   112645939  112663825  112658362  112658412      +   \n",
       "1  C11orf58   11    16613132   16758340   16738643   16738693      +   \n",
       "2    ZSCAN9    6    28224886   28233487   28225263   28225313      +   \n",
       "\n",
       "           gex  cell_line  \n",
       "0     0.000000          1  \n",
       "1  2239.103328          1  \n",
       "2    19.798064          1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_chr=[5,20]\n",
    "test_chr=[2]\n",
    "train_chr=[i for i in range(1,23) if (i not in valid_chr+test_chr)]\n",
    "logging.info(f\"train_chr:{train_chr}valid_chr:{valid_chr}test_chr:{test_chr}\")\n",
    "\n",
    "all_genes = load_train_genes()\n",
    "all_genes.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get genes\n",
    "train_genes=filter_genes_by_chr(all_genes,train_chr)\n",
    "valid_genes=filter_genes_by_chr(all_genes,valid_chr)\n",
    "test_genes=filter_genes_by_chr(all_genes,test_chr)\n",
    "\n",
    "train_genes=train_genes.iloc[0:5000,:] # for testing reason\n",
    "\n",
    "n_genes_train, _ = np.shape(train_genes)\n",
    "n_genes_valid, _ = np.shape(valid_genes)\n",
    "n_genes_test, _ = np.shape(test_genes)\n",
    "logging.info(f\"train_genes.shape:{train_genes.shape}valid_genes.shape:{valid_genes.shape}test_genes.shape:{test_genes.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get genes\n",
    "# total_train_genes, test_genes = chromosome_splits(test_size=0.01)\n",
    "# n_total_train_genes=total_train_genes.shape[0]\n",
    "# train_genes = total_train_genes.iloc[0:int(0.8*n_total_train_genes),:]\n",
    "# valid_genes = total_train_genes.iloc[int(0.8*n_total_train_genes):,:]\n",
    "\n",
    "# n_genes_train, _ = np.shape(train_genes)\n",
    "# n_genes_valid, _ = np.shape(valid_genes)\n",
    "# n_genes_test, _ = np.shape(test_genes)\n",
    "# print(train_genes.shape,valid_genes.shape,test_genes.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_flank_size = 1000#500#1000\n",
    "right_flank_size = 1000#500#1000\n",
    "seq_bin_size=left_flank_size+right_flank_size\n",
    "histone_bin_size = 100 #100 ,20 ,5,1\n",
    "\n",
    "seq_bins=seq_bin_size\n",
    "assert seq_bin_size % histone_bin_size==0\n",
    "histone_bins=int(seq_bin_size/histone_bin_size)\n",
    "logging.info(f\"seq_bins:{seq_bins}histone_bins:{histone_bins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.46 s, sys: 1.2 s, total: 5.66 s\n",
      "Wall time: 5.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load train data\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    HistoneDataset_returngenenames(train_genes,left_flank_size=left_flank_size,right_flank_size=right_flank_size,bin_size=histone_bin_size,use_seq=True), \n",
    "    shuffle=False, batch_size=n_genes_train)\n",
    "\n",
    "# Load valid data\n",
    "valid_dataloader = torch.utils.data.DataLoader(\n",
    "    HistoneDataset_returngenenames(valid_genes,left_flank_size=left_flank_size,right_flank_size=right_flank_size,bin_size=histone_bin_size,use_seq=True), \n",
    "    shuffle=False, batch_size=n_genes_valid)\n",
    "\n",
    "# Load test data\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    HistoneDataset_returngenenames(test_genes,left_flank_size=left_flank_size,right_flank_size=right_flank_size,bin_size=histone_bin_size,use_seq=True), \n",
    "    shuffle=False, batch_size=n_genes_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.6 s, sys: 410 ms, total: 30 s\n",
      "Wall time: 30 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# Run train loader\n",
    "x_train_histone,x_train_seq,y_train,train_index=get_reshaped_data(dataloader=train_dataloader)\n",
    "\n",
    "# Run valid loader\n",
    "x_valid_histone,x_valid_seq,y_valid,valid_index=get_reshaped_data(dataloader=valid_dataloader)\n",
    "\n",
    "# Run test loader\n",
    "x_test_histone,x_test_seq,y_test,test_index=get_reshaped_data(dataloader=test_dataloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 2748 2406\n"
     ]
    }
   ],
   "source": [
    "print(len(train_index),len(valid_index),len(test_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_dict= get_dict_from_data(train_index,valid_index,test_index,\n",
    "                             x_train_seq,x_valid_seq,x_test_seq)\n",
    "\n",
    "histone_dict= get_dict_from_data(train_index,valid_index,test_index,\n",
    "                             x_train_histone,x_valid_histone,x_test_histone)\n",
    "gex_dict = get_dict_from_data(train_index,valid_index,test_index,\n",
    "                             y_train,y_valid,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(dna_dict['1_FERMT2'].shape,histone_dict['1_FERMT2'].shape,gex_dict['1_FERMT2'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "\n",
    "batchsize=50#10000 # 20, 30\n",
    "epochs=1 #50\n",
    "\n",
    "logging.info('Begin training model...')\n",
    "if prefix==\"basic-model-\":#\"opt1-model-\" \"basic-model-\"\n",
    "\tmodel = DeepHistone(use_gpu,bin_list=[seq_bins,histone_bins])\n",
    "elif prefix==\"opt1-model-\":\n",
    "\tmodel = DeepHistone_opt1(use_gpu,bin_list=[seq_bins,histone_bins])\n",
    "best_model = copy.deepcopy(model)\n",
    "best_valid_spearmanr=0\n",
    "best_valid_loss = float('Inf')\n",
    "\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "\tnp.random.shuffle(train_index)\n",
    "\ttrain_loss= model_train(train_index,model,batchsize,dna_dict,histone_dict,gex_dict,)\n",
    "\tvalid_loss,valid_gex,valid_pred= model_eval(valid_index, model,batchsize,dna_dict,histone_dict,gex_dict,)\n",
    "\tvalid_spearmanr= scipy.stats.spearmanr(valid_pred , valid_gex ).correlation\n",
    "\tlogging.info(f\"epoch:{epoch} valid_loss:{valid_loss} valid_spearmanr:{valid_spearmanr}\")\n",
    "\tif valid_spearmanr >best_valid_spearmanr:\n",
    "\t\tbest_model = copy.deepcopy(model)\n",
    "\n",
    "\tif valid_loss < best_valid_loss: \n",
    "\t\tearly_stop_time = 0\n",
    "\t\tbest_valid_loss = valid_loss\t\n",
    "\telse:\n",
    "\t\tmodel.updateLR(0.1)\n",
    "\t\tearly_stop_time += 1\n",
    "\t\tif early_stop_time >= 5: break\n",
    "\n",
    "\tlogging.info(f\"early_stop_time:{early_stop_time}\")\n",
    " \n",
    "\n",
    "# DeepHistone(Dense,Dense) is used.\n",
    "# self.bins 2000\n",
    "# self.out_size:128000\n",
    "# self.bins 20\n",
    "# self.out_size:1280\n",
    "# combined_len: 129280\n",
    "#   0%|                                                    | 0/1 [00:00<?, ?it/s]\n",
    "# batch_idx: 0\n",
    "# self.SeqOrDnase: seq ;self.seq.size torch.Size([50, 1, 4, 2000])\n",
    "# self.conv1.size torch.Size([50, 128, 1, 2000])\n",
    "# self.block1.size torch.Size([50, 512, 1, 2000])\n",
    "# self.trans1.size torch.Size([50, 256, 1, 500])\n",
    "# seq.out.size: 50 256 1 500\n",
    "# flat_seq.size: torch.Size([50, 128000])\n",
    "# dns.size: 50 7 20\n",
    "# self.SeqOrDnase: dnase ;self.seq.size torch.Size([50, 1, 7, 20])\n",
    "# self.conv1.size torch.Size([50, 128, 1, 20])\n",
    "# self.block1.size torch.Size([50, 512, 1, 20])\n",
    "# self.trans1.size torch.Size([50, 256, 1, 5])\n",
    "# dnase.out.size: 50 256 1 5\n",
    "# flat_dns.size torch.Size([50, 1280])\n",
    "# combined.size: torch.Size([50, 129280])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation Score: 0.6174819305753333\n"
     ]
    }
   ],
   "source": [
    "('Begin predicting...')\n",
    "test_gex,test_pred = model_predict(test_index,best_model,batchsize,dna_dict,histone_dict,gex_dict,)\t\n",
    "test_score = scipy.stats.spearmanr(test_pred , test_gex ).correlation\n",
    "\n",
    "print('Spearman Correlation Score: {}'.format(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation Score: 0.7127891842974753\n"
     ]
    }
   ],
   "source": [
    "('Begin predicting...')\n",
    "test_gex,test_pred = model_predict(test_index,model,batchsize,dna_dict,histone_dict,gex_dict,)\t\n",
    "test_score = scipy.stats.spearmanr(test_pred , test_gex ).correlation\n",
    "\n",
    "print('Spearman Correlation Score: {}'.format(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of NetDeepHistone_opt1(\n",
      "  (seq_map): ModuleDense_opt1(\n",
      "    (conv1): Sequential(\n",
      "      (0): Conv2d(1, 128, kernel_size=(4, 9), stride=(1, 1), padding=(0, 4))\n",
      "    )\n",
      "    (block1): DenseBlock(\n",
      "      (layer): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (block): Sequential(\n",
      "            (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1): ReLU()\n",
      "            (2): Conv2d(128, 128, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4))\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (block): Sequential(\n",
      "            (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1): ReLU()\n",
      "            (2): Conv2d(256, 128, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4))\n",
      "          )\n",
      "        )\n",
      "        (2): BasicBlock(\n",
      "          (block): Sequential(\n",
      "            (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1): ReLU()\n",
      "            (2): Conv2d(384, 128, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (trans1): Sequential(\n",
      "      (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (3): MaxPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (dns_map): ModuleDense_opt1(\n",
      "    (conv1): Sequential(\n",
      "      (0): Conv2d(1, 128, kernel_size=(7, 9), stride=(1, 1), padding=(0, 4))\n",
      "    )\n",
      "    (block1): DenseBlock(\n",
      "      (layer): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (block): Sequential(\n",
      "            (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1): ReLU()\n",
      "            (2): Conv2d(128, 128, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4))\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (block): Sequential(\n",
      "            (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1): ReLU()\n",
      "            (2): Conv2d(256, 128, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4))\n",
      "          )\n",
      "        )\n",
      "        (2): BasicBlock(\n",
      "          (block): Sequential(\n",
      "            (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1): ReLU()\n",
      "            (2): Conv2d(384, 128, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (trans1): Sequential(\n",
      "      (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (3): MaxPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (linear_map): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=32256, out_features=925, bias=True)\n",
      "    (2): BatchNorm1d(925, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=925, out_features=1, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "print(model.forward_fn.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Sequential: 1-1                        --\n",
      "|    └─Conv2d: 2-1                       4,736\n",
      "├─DenseBlock: 1-2                        --\n",
      "|    └─Sequential: 2-2                   --\n",
      "|    |    └─BasicBlock: 3-1              147,840\n",
      "|    |    └─BasicBlock: 3-2              295,552\n",
      "|    |    └─BasicBlock: 3-3              443,264\n",
      "├─Sequential: 1-3                        --\n",
      "|    └─BatchNorm2d: 2-3                  1,024\n",
      "|    └─ReLU: 2-4                         --\n",
      "|    └─Conv2d: 2-5                       131,328\n",
      "|    └─MaxPool2d: 2-6                    --\n",
      "├─DenseBlock: 1-4                        --\n",
      "|    └─Sequential: 2-7                   --\n",
      "|    |    └─BasicBlock: 3-4              590,592\n",
      "|    |    └─BasicBlock: 3-5              1,180,928\n",
      "|    |    └─BasicBlock: 3-6              1,771,264\n",
      "├─Sequential: 1-5                        --\n",
      "|    └─BatchNorm2d: 2-8                  2,048\n",
      "|    └─ReLU: 2-9                         --\n",
      "|    └─Conv2d: 2-10                      524,800\n",
      "|    └─MaxPool2d: 2-11                   --\n",
      "=================================================================\n",
      "Total params: 5,093,376\n",
      "Trainable params: 5,093,376\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "├─Sequential: 1-1                        --\n",
       "|    └─Conv2d: 2-1                       4,736\n",
       "├─DenseBlock: 1-2                        --\n",
       "|    └─Sequential: 2-2                   --\n",
       "|    |    └─BasicBlock: 3-1              147,840\n",
       "|    |    └─BasicBlock: 3-2              295,552\n",
       "|    |    └─BasicBlock: 3-3              443,264\n",
       "├─Sequential: 1-3                        --\n",
       "|    └─BatchNorm2d: 2-3                  1,024\n",
       "|    └─ReLU: 2-4                         --\n",
       "|    └─Conv2d: 2-5                       131,328\n",
       "|    └─MaxPool2d: 2-6                    --\n",
       "├─DenseBlock: 1-4                        --\n",
       "|    └─Sequential: 2-7                   --\n",
       "|    |    └─BasicBlock: 3-4              590,592\n",
       "|    |    └─BasicBlock: 3-5              1,180,928\n",
       "|    |    └─BasicBlock: 3-6              1,771,264\n",
       "├─Sequential: 1-5                        --\n",
       "|    └─BatchNorm2d: 2-8                  2,048\n",
       "|    └─ReLU: 2-9                         --\n",
       "|    └─Conv2d: 2-10                      524,800\n",
       "|    └─MaxPool2d: 2-11                   --\n",
       "=================================================================\n",
       "Total params: 5,093,376\n",
       "Trainable params: 5,093,376\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model.forward_fn.seq_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin saving...\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print('Begin saving...')\n",
    "# np.savetxt(f\"{model_save_folder}label.txt\", valid_gex, fmt='%d', delimiter='\\t')\n",
    "# np.savetxt(f\"{model_save_folder}pred.txt\", valid_pred, fmt='%.4f', delimiter='\\t')\n",
    "# save_model(model=best_model,epoch=epoch,seq_bins=seq_bins,histone_bins=histone_bins,\n",
    "#             model_save_folder=model_save_folder,prefix=\"\",suffix=\"best\")\n",
    "# save_model(model=best_model,epoch=epoch,seq_bins=seq_bins,histone_bins=histone_bins,\n",
    "#             model_save_folder=model_save_folder,prefix=\"\",suffix=\"final\")\n",
    "\n",
    "# print('Finished.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "11ff37c28d4f6fe1b94899dc6ccf4d7433e89e2e19d270febc0e861592db34d3"
  },
  "kernelspec": {
   "display_name": "py309_MLG",
   "language": "python",
   "name": "py309_mlg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
