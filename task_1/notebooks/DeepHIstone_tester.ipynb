{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/mnemo5/tao/MLG/task_1/utils\n"
     ]
    }
   ],
   "source": [
    "%cd  /mnt/mnemo5/tao/MLG/task_1/utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  use DeepHistone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import time\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "from data_loader import *\n",
    "from dataset import HistoneDataset_returngenenames\n",
    "from histone_loader import*\n",
    "from stratification import *\n",
    "\n",
    "\n",
    "from modified_DeepHistone_model import DeepHistone\n",
    "from DeepHistone_opt1 import DeepHistone_opt1\n",
    "from modified_DeepHistone_utils import model_train,model_eval,model_predict\n",
    "from modified_DeepHistone_utils import get_reshaped_data\n",
    "from modified_DeepHistone_utils import get_dict_from_data\n",
    "from modified_DeepHistone_utils import save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_save_folder=\"../data/DeepHistone/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_stamp=time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "Log_Format = \"%(levelname)s %(asctime)s - %(message)s\"\n",
    "logging.basicConfig(level=logging.INFO, filename=f\"{model_save_folder}juypter_{prefix}time{time_stamp}.log\",\n",
    "                    filemode=\"a\",format=Log_Format) # cant save into file in jupyter notebook through "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix=\"basic-model-\"#\"opt1-model-\" #\"basic-model-\"\n",
    "use_seq=False\n",
    "\n",
    "logging.info(f\"model:{prefix}use_seq:{use_seq}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_name</th>\n",
       "      <th>chr</th>\n",
       "      <th>gene_start</th>\n",
       "      <th>gene_end</th>\n",
       "      <th>TSS_start</th>\n",
       "      <th>TSS_end</th>\n",
       "      <th>strand</th>\n",
       "      <th>gex</th>\n",
       "      <th>cell_line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SLC20A1</td>\n",
       "      <td>2</td>\n",
       "      <td>112645939</td>\n",
       "      <td>112663825</td>\n",
       "      <td>112658362</td>\n",
       "      <td>112658412</td>\n",
       "      <td>+</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C11orf58</td>\n",
       "      <td>11</td>\n",
       "      <td>16613132</td>\n",
       "      <td>16758340</td>\n",
       "      <td>16738643</td>\n",
       "      <td>16738693</td>\n",
       "      <td>+</td>\n",
       "      <td>2239.103328</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZSCAN9</td>\n",
       "      <td>6</td>\n",
       "      <td>28224886</td>\n",
       "      <td>28233487</td>\n",
       "      <td>28225263</td>\n",
       "      <td>28225313</td>\n",
       "      <td>+</td>\n",
       "      <td>19.798064</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gene_name  chr  gene_start   gene_end  TSS_start    TSS_end strand  \\\n",
       "0   SLC20A1    2   112645939  112663825  112658362  112658412      +   \n",
       "1  C11orf58   11    16613132   16758340   16738643   16738693      +   \n",
       "2    ZSCAN9    6    28224886   28233487   28225263   28225313      +   \n",
       "\n",
       "           gex  cell_line  \n",
       "0     0.000000          1  \n",
       "1  2239.103328          1  \n",
       "2    19.798064          1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_chr=[5,20]\n",
    "test_chr=[2]\n",
    "train_chr=[i for i in range(1,23) if (i not in valid_chr+test_chr)]\n",
    "logging.info(f\"train_chr:{train_chr}valid_chr:{valid_chr}test_chr:{test_chr}\")\n",
    "\n",
    "all_genes = load_train_genes()\n",
    "all_genes.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get genes\n",
    "train_genes=filter_genes_by_chr(all_genes,train_chr)\n",
    "valid_genes=filter_genes_by_chr(all_genes,valid_chr)\n",
    "test_genes=filter_genes_by_chr(all_genes,test_chr)\n",
    "\n",
    "train_genes=train_genes.iloc[0:5000,:] # for testing reason\n",
    "\n",
    "n_genes_train, _ = np.shape(train_genes)\n",
    "n_genes_valid, _ = np.shape(valid_genes)\n",
    "n_genes_test, _ = np.shape(test_genes)\n",
    "logging.info(f\"train_genes.shape:{train_genes.shape}valid_genes.shape:{valid_genes.shape}test_genes.shape:{test_genes.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get genes\n",
    "# total_train_genes, test_genes = chromosome_splits(test_size=0.01)\n",
    "# n_total_train_genes=total_train_genes.shape[0]\n",
    "# train_genes = total_train_genes.iloc[0:int(0.8*n_total_train_genes),:]\n",
    "# valid_genes = total_train_genes.iloc[int(0.8*n_total_train_genes):,:]\n",
    "\n",
    "# n_genes_train, _ = np.shape(train_genes)\n",
    "# n_genes_valid, _ = np.shape(valid_genes)\n",
    "# n_genes_test, _ = np.shape(test_genes)\n",
    "# print(train_genes.shape,valid_genes.shape,test_genes.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_flank_size = 1000#500#1000\n",
    "right_flank_size = 1000#500#1000\n",
    "seq_bin_size=left_flank_size+right_flank_size\n",
    "histone_bin_size = 100 #100 ,20 ,5,1\n",
    "\n",
    "seq_bins=seq_bin_size\n",
    "assert seq_bin_size % histone_bin_size==0\n",
    "histone_bins=int(seq_bin_size/histone_bin_size)\n",
    "logging.info(f\"seq_bins:{seq_bins}histone_bins:{histone_bins}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.16 s, sys: 4.68 s, total: 12.8 s\n",
      "Wall time: 13.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load train data\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    HistoneDataset_returngenenames(train_genes,left_flank_size=left_flank_size,right_flank_size=right_flank_size,bin_size=histone_bin_size,use_seq=True), \n",
    "    shuffle=False, batch_size=n_genes_train)\n",
    "\n",
    "# Load valid data\n",
    "valid_dataloader = torch.utils.data.DataLoader(\n",
    "    HistoneDataset_returngenenames(valid_genes,left_flank_size=left_flank_size,right_flank_size=right_flank_size,bin_size=histone_bin_size,use_seq=True), \n",
    "    shuffle=False, batch_size=n_genes_valid)\n",
    "\n",
    "# Load test data\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    HistoneDataset_returngenenames(test_genes,left_flank_size=left_flank_size,right_flank_size=right_flank_size,bin_size=histone_bin_size,use_seq=True), \n",
    "    shuffle=False, batch_size=n_genes_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.1 s, sys: 416 ms, total: 32.5 s\n",
      "Wall time: 32.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# Run train loader\n",
    "x_train_histone,x_train_seq,y_train,train_index=get_reshaped_data(dataloader=train_dataloader)\n",
    "\n",
    "# Run valid loader\n",
    "x_valid_histone,x_valid_seq,y_valid,valid_index=get_reshaped_data(dataloader=valid_dataloader)\n",
    "\n",
    "# Run test loader\n",
    "x_test_histone,x_test_seq,y_test,test_index=get_reshaped_data(dataloader=test_dataloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 2748 2406\n"
     ]
    }
   ],
   "source": [
    "print(len(train_index),len(valid_index),len(test_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "dna_dict= get_dict_from_data(train_index,valid_index,test_index,\n",
    "                             x_train_seq,x_valid_seq,x_test_seq)\n",
    "\n",
    "histone_dict= get_dict_from_data(train_index,valid_index,test_index,\n",
    "                             x_train_histone,x_valid_histone,x_test_histone)\n",
    "gex_dict = get_dict_from_data(train_index,valid_index,test_index,\n",
    "                             y_train,y_valid,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(dna_dict['1_FERMT2'].shape,histone_dict['1_FERMT2'].shape,gex_dict['1_FERMT2'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx: 0\n",
      "batch_idx: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/1 [14:46<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(epochs)):\n\u001b[1;32m     26\u001b[0m \tnp\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mshuffle(train_index)\n\u001b[0;32m---> 27\u001b[0m \ttrain_loss\u001b[38;5;241m=\u001b[39m \u001b[43mmodel_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatchsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdna_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhistone_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgex_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \tvalid_loss,valid_gex,valid_pred\u001b[38;5;241m=\u001b[39m model_eval(valid_index, model,batchsize,dna_dict,histone_dict,gex_dict,)\n\u001b[1;32m     29\u001b[0m \tvalid_spearmanr\u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39mstats\u001b[38;5;241m.\u001b[39mspearmanr(valid_pred , valid_gex )\u001b[38;5;241m.\u001b[39mcorrelation\n",
      "File \u001b[0;32m~/MLG/task_1/utils/modified_DeepHistone_utils.py:84\u001b[0m, in \u001b[0;36mmodel_train\u001b[0;34m(regions, model, batchsize, dna_dict, dns_dict, label_dict)\u001b[0m\n\u001b[1;32m     82\u001b[0m \t\u001b[38;5;66;03m#print(\"region_batch: \",(regions_batch))\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \tseq_batch ,dns_batch,lab_batch \u001b[38;5;241m=\u001b[39m loadRegions(regions_batch,dna_dict,dns_dict,label_dict)\n\u001b[0;32m---> 84\u001b[0m \t_loss\u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdns_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlab_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \ttrain_loss\u001b[38;5;241m.\u001b[39mappend(_loss)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(train_loss)\n",
      "File \u001b[0;32m~/MLG/task_1/utils/modified_DeepHistone_model.py:188\u001b[0m, in \u001b[0;36mDeepHistone.train_on_batch\u001b[0;34m(self, seq_batch, dns_batch, lab_batch)\u001b[0m\n\u001b[1;32m    186\u001b[0m lab_batch  \u001b[38;5;241m=\u001b[39m Variable(torch\u001b[38;5;241m.\u001b[39mTensor(lab_batch))\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_gpu: seq_batch, dns_batch, lab_batch \u001b[38;5;241m=\u001b[39m seq_batch\u001b[38;5;241m.\u001b[39mcuda(), dns_batch\u001b[38;5;241m.\u001b[39mcuda(), lab_batch\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m--> 188\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdns_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(output,lab_batch)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/anaconda3/envs/py309_MLG/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/MLG/task_1/utils/modified_DeepHistone_model.py:134\u001b[0m, in \u001b[0;36mNetDeepHistone.forward\u001b[0;34m(self, seq, dns)\u001b[0m\n\u001b[1;32m    132\u001b[0m dns_n, dns_h, dns_w \u001b[38;5;241m=\u001b[39m dns\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m#print(\"dns.size:\",dns_n,dns_h,dns_w)\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m dns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdns_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdns\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m#print(\"dns.size:\",dns.size())\u001b[39;00m\n\u001b[1;32m    136\u001b[0m flat_dns \u001b[38;5;241m=\u001b[39m dns\u001b[38;5;241m.\u001b[39mview(dns_n,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# so here actully is strang , why seq not needed flatting ?\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/py309_MLG/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/MLG/task_1/utils/modified_DeepHistone_model.py:85\u001b[0m, in \u001b[0;36mModuleDense.forward\u001b[0;34m(self, seq)\u001b[0m\n\u001b[1;32m     83\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock1(out)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m#print(\"self.block1.size\",out.size())\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrans1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m#print(\"self.trans1.size\",out.size())\u001b[39;00m\n\u001b[1;32m     87\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock2(out)\n",
      "File \u001b[0;32m~/anaconda3/envs/py309_MLG/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/py309_MLG/lib/python3.9/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/py309_MLG/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/py309_MLG/lib/python3.9/site-packages/torch/nn/modules/conv.py:446\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py309_MLG/lib/python3.9/site-packages/torch/nn/modules/conv.py:442\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    440\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    441\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 442\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "\n",
    "batchsize=50#10000 # 20, 30\n",
    "epochs=1 #50\n",
    "\n",
    "conv_ksize,tran_ksize=9,4 \n",
    "logging.info(f\"conv_ksize:{conv_ksize}tran_ksize:{tran_ksize}\")\n",
    "\n",
    "\n",
    "logging.info('Begin training model...')\n",
    "\n",
    "if prefix==\"basic-model-\":#\"opt1-model-\" \"basic-model-\"\n",
    "\tmodel = DeepHistone(use_gpu,use_seq=use_seq,bin_list=[seq_bins,histone_bins],inside_ksize=[conv_ksize,tran_ksize])\n",
    "elif prefix==\"opt1-model-\":\n",
    "\tmodel = DeepHistone_opt1(use_gpu,bin_list=[seq_bins,histone_bins])\n",
    "    \n",
    "    \n",
    "best_model = copy.deepcopy(model)\n",
    "best_valid_spearmanr=0\n",
    "best_valid_loss = float('Inf')\n",
    "\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "\tnp.random.shuffle(train_index)\n",
    "\ttrain_loss= model_train(train_index,model,batchsize,dna_dict,histone_dict,gex_dict,)\n",
    "\tvalid_loss,valid_gex,valid_pred= model_eval(valid_index, model,batchsize,dna_dict,histone_dict,gex_dict,)\n",
    "\tvalid_spearmanr= scipy.stats.spearmanr(valid_pred , valid_gex ).correlation\n",
    "\tlogging.info(f\"epoch:{epoch} valid_loss:{valid_loss} valid_spearmanr:{valid_spearmanr}\")\n",
    "\tif valid_spearmanr >best_valid_spearmanr:\n",
    "\t\tbest_model = copy.deepcopy(model)\n",
    "\n",
    "\tif valid_loss < best_valid_loss: \n",
    "\t\tearly_stop_time = 0\n",
    "\t\tbest_valid_loss = valid_loss\t\n",
    "\telse:\n",
    "\t\tmodel.updateLR(0.1)\n",
    "\t\tearly_stop_time += 1\n",
    "\t\tif early_stop_time >= 5: break\n",
    "\n",
    "\tlogging.info(f\"early_stop_time:{early_stop_time}\")\n",
    " \n",
    "\n",
    "# DeepHistone(Dense,Dense) is used.\n",
    "# self.bins 2000\n",
    "# self.out_size:128000\n",
    "# self.bins 20\n",
    "# self.out_size:1280\n",
    "# combined_len: 129280\n",
    "#   0%|                                                    | 0/1 [00:00<?, ?it/s]\n",
    "# batch_idx: 0\n",
    "# self.SeqOrDnase: seq ;self.seq.size torch.Size([50, 1, 4, 2000])\n",
    "# self.conv1.size torch.Size([50, 128, 1, 2000])\n",
    "# self.block1.size torch.Size([50, 512, 1, 2000])\n",
    "# self.trans1.size torch.Size([50, 256, 1, 500])\n",
    "# seq.out.size: 50 256 1 500\n",
    "# flat_seq.size: torch.Size([50, 128000])\n",
    "# dns.size: 50 7 20\n",
    "# self.SeqOrDnase: dnase ;self.seq.size torch.Size([50, 1, 7, 20])\n",
    "# self.conv1.size torch.Size([50, 128, 1, 20])\n",
    "# self.block1.size torch.Size([50, 512, 1, 20])\n",
    "# self.trans1.size torch.Size([50, 256, 1, 5])\n",
    "# dnase.out.size: 50 256 1 5\n",
    "# flat_dns.size torch.Size([50, 1280])\n",
    "# combined.size: torch.Size([50, 129280])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation Score: 0.6174819305753333\n"
     ]
    }
   ],
   "source": [
    "('Begin predicting...')\n",
    "test_gex,test_pred = model_predict(test_index,best_model,batchsize,dna_dict,histone_dict,gex_dict,)\t\n",
    "test_score = scipy.stats.spearmanr(test_pred , test_gex ).correlation\n",
    "\n",
    "print('Spearman Correlation Score: {}'.format(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation Score: 0.7127891842974753\n"
     ]
    }
   ],
   "source": [
    "('Begin predicting...')\n",
    "test_gex,test_pred = model_predict(test_index,model,batchsize,dna_dict,histone_dict,gex_dict,)\t\n",
    "test_score = scipy.stats.spearmanr(test_pred , test_gex ).correlation\n",
    "\n",
    "print('Spearman Correlation Score: {}'.format(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of NetDeepHistone_opt1(\n",
      "  (seq_map): ModuleDense_opt1(\n",
      "    (conv1): Sequential(\n",
      "      (0): Conv2d(1, 128, kernel_size=(4, 9), stride=(1, 1), padding=(0, 4))\n",
      "    )\n",
      "    (block1): DenseBlock(\n",
      "      (layer): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (block): Sequential(\n",
      "            (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1): ReLU()\n",
      "            (2): Conv2d(128, 128, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4))\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (block): Sequential(\n",
      "            (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1): ReLU()\n",
      "            (2): Conv2d(256, 128, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4))\n",
      "          )\n",
      "        )\n",
      "        (2): BasicBlock(\n",
      "          (block): Sequential(\n",
      "            (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1): ReLU()\n",
      "            (2): Conv2d(384, 128, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (trans1): Sequential(\n",
      "      (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (3): MaxPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (dns_map): ModuleDense_opt1(\n",
      "    (conv1): Sequential(\n",
      "      (0): Conv2d(1, 128, kernel_size=(7, 9), stride=(1, 1), padding=(0, 4))\n",
      "    )\n",
      "    (block1): DenseBlock(\n",
      "      (layer): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (block): Sequential(\n",
      "            (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1): ReLU()\n",
      "            (2): Conv2d(128, 128, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4))\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (block): Sequential(\n",
      "            (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1): ReLU()\n",
      "            (2): Conv2d(256, 128, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4))\n",
      "          )\n",
      "        )\n",
      "        (2): BasicBlock(\n",
      "          (block): Sequential(\n",
      "            (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1): ReLU()\n",
      "            (2): Conv2d(384, 128, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (trans1): Sequential(\n",
      "      (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (3): MaxPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (linear_map): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=32256, out_features=925, bias=True)\n",
      "    (2): BatchNorm1d(925, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=925, out_features=1, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "print(model.forward_fn.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Sequential: 1-1                        --\n",
      "|    └─Conv2d: 2-1                       4,736\n",
      "├─DenseBlock: 1-2                        --\n",
      "|    └─Sequential: 2-2                   --\n",
      "|    |    └─BasicBlock: 3-1              147,840\n",
      "|    |    └─BasicBlock: 3-2              295,552\n",
      "|    |    └─BasicBlock: 3-3              443,264\n",
      "├─Sequential: 1-3                        --\n",
      "|    └─BatchNorm2d: 2-3                  1,024\n",
      "|    └─ReLU: 2-4                         --\n",
      "|    └─Conv2d: 2-5                       131,328\n",
      "|    └─MaxPool2d: 2-6                    --\n",
      "├─DenseBlock: 1-4                        --\n",
      "|    └─Sequential: 2-7                   --\n",
      "|    |    └─BasicBlock: 3-4              590,592\n",
      "|    |    └─BasicBlock: 3-5              1,180,928\n",
      "|    |    └─BasicBlock: 3-6              1,771,264\n",
      "├─Sequential: 1-5                        --\n",
      "|    └─BatchNorm2d: 2-8                  2,048\n",
      "|    └─ReLU: 2-9                         --\n",
      "|    └─Conv2d: 2-10                      524,800\n",
      "|    └─MaxPool2d: 2-11                   --\n",
      "=================================================================\n",
      "Total params: 5,093,376\n",
      "Trainable params: 5,093,376\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "├─Sequential: 1-1                        --\n",
       "|    └─Conv2d: 2-1                       4,736\n",
       "├─DenseBlock: 1-2                        --\n",
       "|    └─Sequential: 2-2                   --\n",
       "|    |    └─BasicBlock: 3-1              147,840\n",
       "|    |    └─BasicBlock: 3-2              295,552\n",
       "|    |    └─BasicBlock: 3-3              443,264\n",
       "├─Sequential: 1-3                        --\n",
       "|    └─BatchNorm2d: 2-3                  1,024\n",
       "|    └─ReLU: 2-4                         --\n",
       "|    └─Conv2d: 2-5                       131,328\n",
       "|    └─MaxPool2d: 2-6                    --\n",
       "├─DenseBlock: 1-4                        --\n",
       "|    └─Sequential: 2-7                   --\n",
       "|    |    └─BasicBlock: 3-4              590,592\n",
       "|    |    └─BasicBlock: 3-5              1,180,928\n",
       "|    |    └─BasicBlock: 3-6              1,771,264\n",
       "├─Sequential: 1-5                        --\n",
       "|    └─BatchNorm2d: 2-8                  2,048\n",
       "|    └─ReLU: 2-9                         --\n",
       "|    └─Conv2d: 2-10                      524,800\n",
       "|    └─MaxPool2d: 2-11                   --\n",
       "=================================================================\n",
       "Total params: 5,093,376\n",
       "Trainable params: 5,093,376\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model.forward_fn.seq_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin saving...\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print('Begin saving...')\n",
    "# np.savetxt(f\"{model_save_folder}label.txt\", valid_gex, fmt='%d', delimiter='\\t')\n",
    "# np.savetxt(f\"{model_save_folder}pred.txt\", valid_pred, fmt='%.4f', delimiter='\\t')\n",
    "# save_model(model=best_model,epoch=epoch,seq_bins=seq_bins,histone_bins=histone_bins,\n",
    "#             model_save_folder=model_save_folder,prefix=\"\",suffix=\"best\")\n",
    "# save_model(model=best_model,epoch=epoch,seq_bins=seq_bins,histone_bins=histone_bins,\n",
    "#             model_save_folder=model_save_folder,prefix=\"\",suffix=\"final\")\n",
    "\n",
    "# print('Finished.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "11ff37c28d4f6fe1b94899dc6ccf4d7433e89e2e19d270febc0e861592db34d3"
  },
  "kernelspec": {
   "display_name": "py309_MLG",
   "language": "python",
   "name": "py309_mlg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
