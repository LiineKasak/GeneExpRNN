{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/net/cephfs/home/tfang/MLG/task_1/utils\n"
     ]
    }
   ],
   "source": [
    "%cd  ../utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  use DeepHistone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import time\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "from data_loader import *\n",
    "from dataset import HistoneDataset_returngenenames\n",
    "from histone_loader import*\n",
    "from stratification import *\n",
    "\n",
    "\n",
    "from modified_DeepHistone_model import DeepHistone\n",
    "from DeepHistone_opt1 import DeepHistone_opt1\n",
    "from modified_DeepHistone_utils import model_train,model_eval,model_predict\n",
    "from modified_DeepHistone_utils import get_reshaped_data\n",
    "from modified_DeepHistone_utils import get_dict_from_data\n",
    "from modified_DeepHistone_utils import save_model\n",
    "from modified_DeepHistone_utils import get_compplex_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_save_folder=\"../data/DeepHistone/\"\n",
    "prefix=\"basic-model-\"#\"opt1-model-\" #\"basic-model-\"\n",
    "\n",
    "\n",
    "left_flank_size = 1000#500#1000\n",
    "right_flank_size = left_flank_size#500#1000\n",
    "seq_bin_size=left_flank_size+right_flank_size\n",
    "histone_bin_size = 100 #100 ,20 ,5,1\n",
    "\n",
    "seq_bins=seq_bin_size\n",
    "assert seq_bin_size % histone_bin_size==0\n",
    "histone_bins=int(seq_bin_size/histone_bin_size)\n",
    "\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "\n",
    "batchsize=50#10000 # 20, 30\n",
    "epochs=1 #50\n",
    "\n",
    "conv_ksize,tran_ksize=9,4 \n",
    "\n",
    "use_seq=False\n",
    "\n",
    "prefix=get_compplex_prefix(prefix=prefix,use_seq=use_seq,\n",
    "                           left_flank_size =left_flank_size,histone_bin_size=histone_bin_size,\n",
    "                           conv_ksize=conv_ksize,tran_ksize=tran_ksize,\n",
    "                           batchsize=batchsize,epochs=epochs,\n",
    "                           use_gpu=use_gpu,)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_stamp=time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "Log_Format = \"%(levelname)s %(asctime)s - %(message)s\"\n",
    "logging.basicConfig(level=logging.INFO, filename=f\"{model_save_folder}{prefix}time{time_stamp}.log\",\n",
    "                    filemode=\"a\",format=Log_Format) # cant save into file in jupyter notebook through "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_name</th>\n",
       "      <th>chr</th>\n",
       "      <th>gene_start</th>\n",
       "      <th>gene_end</th>\n",
       "      <th>TSS_start</th>\n",
       "      <th>TSS_end</th>\n",
       "      <th>strand</th>\n",
       "      <th>gex</th>\n",
       "      <th>cell_line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SLC20A1</td>\n",
       "      <td>2</td>\n",
       "      <td>112645939</td>\n",
       "      <td>112663825</td>\n",
       "      <td>112658362</td>\n",
       "      <td>112658412</td>\n",
       "      <td>+</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C11orf58</td>\n",
       "      <td>11</td>\n",
       "      <td>16613132</td>\n",
       "      <td>16758340</td>\n",
       "      <td>16738643</td>\n",
       "      <td>16738693</td>\n",
       "      <td>+</td>\n",
       "      <td>2239.103328</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZSCAN9</td>\n",
       "      <td>6</td>\n",
       "      <td>28224886</td>\n",
       "      <td>28233487</td>\n",
       "      <td>28225263</td>\n",
       "      <td>28225313</td>\n",
       "      <td>+</td>\n",
       "      <td>19.798064</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gene_name  chr  gene_start   gene_end  TSS_start    TSS_end strand  \\\n",
       "0   SLC20A1    2   112645939  112663825  112658362  112658412      +   \n",
       "1  C11orf58   11    16613132   16758340   16738643   16738693      +   \n",
       "2    ZSCAN9    6    28224886   28233487   28225263   28225313      +   \n",
       "\n",
       "           gex  cell_line  \n",
       "0     0.000000          1  \n",
       "1  2239.103328          1  \n",
       "2    19.798064          1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_chr=[5,20]\n",
    "test_chr=[2]\n",
    "train_chr=[i for i in range(1,23) if (i not in valid_chr+test_chr)]\n",
    "logging.info(f\"train_chr:{train_chr}valid_chr:{valid_chr}test_chr:{test_chr}\")\n",
    "\n",
    "all_genes = load_train_genes()\n",
    "all_genes.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get genes\n",
    "train_genes=filter_genes_by_chr(all_genes,train_chr)\n",
    "valid_genes=filter_genes_by_chr(all_genes,valid_chr)\n",
    "test_genes=filter_genes_by_chr(all_genes,test_chr)\n",
    "\n",
    "train_genes=train_genes.iloc[0:5000,:] # for testing reason\n",
    "\n",
    "n_genes_train, _ = np.shape(train_genes)\n",
    "n_genes_valid, _ = np.shape(valid_genes)\n",
    "n_genes_test, _ = np.shape(test_genes)\n",
    "logging.info(f\"train_genes.shape:{train_genes.shape}valid_genes.shape:{valid_genes.shape}test_genes.shape:{test_genes.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get genes\n",
    "# total_train_genes, test_genes = chromosome_splits(test_size=0.01)\n",
    "# n_total_train_genes=total_train_genes.shape[0]\n",
    "# train_genes = total_train_genes.iloc[0:int(0.8*n_total_train_genes),:]\n",
    "# valid_genes = total_train_genes.iloc[int(0.8*n_total_train_genes):,:]\n",
    "\n",
    "# n_genes_train, _ = np.shape(train_genes)\n",
    "# n_genes_valid, _ = np.shape(valid_genes)\n",
    "# n_genes_test, _ = np.shape(test_genes)\n",
    "# print(train_genes.shape,valid_genes.shape,test_genes.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.73 s, sys: 2.53 s, total: 9.26 s\n",
      "Wall time: 9.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load train data\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    HistoneDataset_returngenenames(train_genes,left_flank_size=left_flank_size,right_flank_size=right_flank_size,bin_size=histone_bin_size,use_seq=True), \n",
    "    shuffle=False, batch_size=n_genes_train)\n",
    "\n",
    "# Load valid data\n",
    "valid_dataloader = torch.utils.data.DataLoader(\n",
    "    HistoneDataset_returngenenames(valid_genes,left_flank_size=left_flank_size,right_flank_size=right_flank_size,bin_size=histone_bin_size,use_seq=True), \n",
    "    shuffle=False, batch_size=n_genes_valid)\n",
    "\n",
    "# Load test data\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    HistoneDataset_returngenenames(test_genes,left_flank_size=left_flank_size,right_flank_size=right_flank_size,bin_size=histone_bin_size,use_seq=True), \n",
    "    shuffle=False, batch_size=n_genes_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.8 s, sys: 421 ms, total: 40.2 s\n",
      "Wall time: 40.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# Run train loader\n",
    "x_train_histone,x_train_seq,y_train,train_index=get_reshaped_data(dataloader=train_dataloader)\n",
    "\n",
    "# Run valid loader\n",
    "x_valid_histone,x_valid_seq,y_valid,valid_index=get_reshaped_data(dataloader=valid_dataloader)\n",
    "\n",
    "# Run test loader\n",
    "x_test_histone,x_test_seq,y_test,test_index=get_reshaped_data(dataloader=test_dataloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 2748 2406\n"
     ]
    }
   ],
   "source": [
    "print(len(train_index),len(valid_index),len(test_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 66.5 ms, sys: 0 ns, total: 66.5 ms\n",
      "Wall time: 66.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "dna_dict= get_dict_from_data(train_index,valid_index,test_index,\n",
    "                             x_train_seq,x_valid_seq,x_test_seq)\n",
    "\n",
    "histone_dict= get_dict_from_data(train_index,valid_index,test_index,\n",
    "                             x_train_histone,x_valid_histone,x_test_histone)\n",
    "gex_dict = get_dict_from_data(train_index,valid_index,test_index,\n",
    "                             y_train,y_valid,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(dna_dict['1_FERMT2'].shape,histone_dict['1_FERMT2'].shape,gex_dict['1_FERMT2'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx: 0\n",
      "batch_idx: 100\n",
      "batch_idx: 200\n",
      "batch_idx: 300\n",
      "batch_idx: 400\n",
      "batch_idx: 500\n",
      "batch_idx: 600\n",
      "batch_idx: 700\n",
      "batch_idx: 800\n",
      "batch_idx: 900\n",
      "batch_idx: 1000\n",
      "batch_idx: 1100\n",
      "batch_idx: 1200\n",
      "batch_idx: 1300\n",
      "batch_idx: 1400\n",
      "batch_idx: 1500\n",
      "batch_idx: 1600\n",
      "batch_idx: 1700\n",
      "batch_idx: 1800\n",
      "batch_idx: 1900\n",
      "batch_idx: 2000\n",
      "batch_idx: 2100\n",
      "batch_idx: 2200\n",
      "batch_idx: 2300\n",
      "batch_idx: 2400\n",
      "batch_idx: 2500\n",
      "batch_idx: 2600\n",
      "batch_idx: 2700\n",
      "batch_idx: 2800\n",
      "batch_idx: 2900\n",
      "batch_idx: 3000\n",
      "batch_idx: 3100\n",
      "batch_idx: 3200\n",
      "batch_idx: 3300\n",
      "batch_idx: 3400\n",
      "batch_idx: 3500\n",
      "batch_idx: 3600\n",
      "batch_idx: 3700\n",
      "batch_idx: 3800\n",
      "batch_idx: 3900\n",
      "batch_idx: 4000\n",
      "batch_idx: 4100\n",
      "batch_idx: 4200\n",
      "batch_idx: 4300\n",
      "batch_idx: 4400\n",
      "batch_idx: 4500\n",
      "batch_idx: 4600\n",
      "batch_idx: 4700\n",
      "batch_idx: 4800\n",
      "batch_idx: 4900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:12<00:00, 12.12s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "logging.info('Begin training model...')\n",
    "\n",
    "if prefix==\"basic-model-\":#\"opt1-model-\" \"basic-model-\"\n",
    "\tmodel = DeepHistone(use_gpu,use_seq=use_seq,bin_list=[seq_bins,histone_bins],inside_ksize=[conv_ksize,tran_ksize])\n",
    "elif prefix==\"opt1-model-\":\n",
    "\tmodel = DeepHistone_opt1(use_gpu,bin_list=[seq_bins,histone_bins])\n",
    "    \n",
    "    \n",
    "best_model = copy.deepcopy(model)\n",
    "best_valid_spearmanr=0\n",
    "best_valid_loss = float('Inf')\n",
    "\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "\tnp.random.shuffle(train_index)\n",
    "\ttrain_loss= model_train(train_index,model,batchsize,dna_dict,histone_dict,gex_dict,)\n",
    "\tvalid_loss,valid_gex,valid_pred= model_eval(valid_index, model,batchsize,dna_dict,histone_dict,gex_dict,)\n",
    "\tvalid_spearmanr= scipy.stats.spearmanr(valid_pred , valid_gex ).correlation\n",
    "\tlogging.info(f\"epoch:{epoch} valid_loss:{valid_loss} valid_spearmanr:{valid_spearmanr}\")\n",
    "\tif valid_spearmanr >best_valid_spearmanr:\n",
    "\t\tbest_model = copy.deepcopy(model)\n",
    "\n",
    "\tif valid_loss < best_valid_loss: \n",
    "\t\tearly_stop_time = 0\n",
    "\t\tbest_valid_loss = valid_loss\t\n",
    "\telse:\n",
    "\t\tmodel.updateLR(0.1)\n",
    "\t\tearly_stop_time += 1\n",
    "\t\tif early_stop_time >= 5: break\n",
    "\n",
    "\tlogging.info(f\"early_stop_time:{early_stop_time}\")\n",
    " \n",
    "\n",
    "# DeepHistone(Dense,Dense) is used.\n",
    "# self.bins 2000\n",
    "# self.out_size:128000\n",
    "# self.bins 20\n",
    "# self.out_size:1280\n",
    "# combined_len: 129280\n",
    "#   0%|                                                    | 0/1 [00:00<?, ?it/s]\n",
    "# batch_idx: 0\n",
    "# self.SeqOrDnase: seq ;self.seq.size torch.Size([50, 1, 4, 2000])\n",
    "# self.conv1.size torch.Size([50, 128, 1, 2000])\n",
    "# self.block1.size torch.Size([50, 512, 1, 2000])\n",
    "# self.trans1.size torch.Size([50, 256, 1, 500])\n",
    "# seq.out.size: 50 256 1 500\n",
    "# flat_seq.size: torch.Size([50, 128000])\n",
    "# dns.size: 50 7 20\n",
    "# self.SeqOrDnase: dnase ;self.seq.size torch.Size([50, 1, 7, 20])\n",
    "# self.conv1.size torch.Size([50, 128, 1, 20])\n",
    "# self.block1.size torch.Size([50, 512, 1, 20])\n",
    "# self.trans1.size torch.Size([50, 256, 1, 5])\n",
    "# dnase.out.size: 50 256 1 5\n",
    "# flat_dns.size torch.Size([50, 1280])\n",
    "# combined.size: torch.Size([50, 129280])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation Score: 0.709273561031794\n"
     ]
    }
   ],
   "source": [
    "('Begin predicting...')\n",
    "test_gex,test_pred = model_predict(test_index,best_model,batchsize,dna_dict,histone_dict,gex_dict,)\t\n",
    "test_score = scipy.stats.spearmanr(test_pred , test_gex ).correlation\n",
    "\n",
    "print('Spearman Correlation Score: {}'.format(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation Score: 0.709273561031794\n"
     ]
    }
   ],
   "source": [
    "('Begin predicting...')\n",
    "test_gex,test_pred = model_predict(test_index,model,batchsize,dna_dict,histone_dict,gex_dict,)\t\n",
    "test_score = scipy.stats.spearmanr(test_pred , test_gex ).correlation\n",
    "\n",
    "print('Spearman Correlation Score: {}'.format(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1287198784.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [5]\u001b[0;36m\u001b[0m\n\u001b[0;31m    final modoel name need to be further refined\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# test job inreactive \n",
    "#module load generic\n",
    "\n",
    "final modoel name need to be further refined \n",
    "\n",
    "module load volta\n",
    "\n",
    "module load volta cuda/11.2 \n",
    "\n",
    "module load volta nvidia/cuda11.2-cudnn8.1.0\n",
    "\n",
    "source activate /data/tfang/conda-envs/py309_MLG\n",
    "\n",
    "srun --pty --time=3:0:0 --mem-per-cpu=100G --cpus-per-task=2 --gres gpu:1 bash -l\n",
    "\n",
    "cancel job : scancel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(model.forward_fn.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary(model.forward_fn.seq_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin saving...\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print('Begin saving...')\n",
    "# np.savetxt(f\"{model_save_folder}label.txt\", valid_gex, fmt='%d', delimiter='\\t')\n",
    "# np.savetxt(f\"{model_save_folder}pred.txt\", valid_pred, fmt='%.4f', delimiter='\\t')\n",
    "# save_model(model=best_model,epoch=epoch,seq_bins=seq_bins,histone_bins=histone_bins,\n",
    "#             model_save_folder=model_save_folder,prefix=\"\",suffix=\"best\")\n",
    "# save_model(model=best_model,epoch=epoch,seq_bins=seq_bins,histone_bins=histone_bins,\n",
    "#             model_save_folder=model_save_folder,prefix=\"\",suffix=\"final\")\n",
    "\n",
    "# print('Finished.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "11ff37c28d4f6fe1b94899dc6ccf4d7433e89e2e19d270febc0e861592db34d3"
  },
  "kernelspec": {
   "display_name": "py309_MLG",
   "language": "python",
   "name": "py309_mlg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
